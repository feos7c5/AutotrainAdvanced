{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yml\n",
    "task: token_classification # do not change\n",
    "base_model: google-bert/bert-base-uncased # the model to be used from hugging face hub\n",
    "project_name: autotrain-token-classification-model # the name of the project, must be unique\n",
    "log: tensorboard # do not change\n",
    "backend: local # do not change\n",
    "\n",
    "data:\n",
    "  path: data/ # the path to the data folder\n",
    "  train_split: train # this folder inside data/ will be used for training\n",
    "  valid_split: null # this folder inside data/ will be used for validation. If not available, set it to null\n",
    "  column_mapping: # do not change\n",
    "    tokens_column: tokens\n",
    "    tags_column: ner_tags\n",
    "\n",
    "params:\n",
    "  epochs: 3\n",
    "  batch_size: 8\n",
    "  max_seq_length: 512\n",
    "  lr: 2e-5\n",
    "  optimizer: adamw_torch\n",
    "  scheduler: linear\n",
    "  gradient_accumulation: 1\n",
    "  mixed_precision: fp16\n",
    "\n",
    "hub:\n",
    "  username: ${HF_USERNAME} # please set HF_USERNAME in colab secrets\n",
    "  token: ${HF_TOKEN} # please set HF_TOKEN in colab secrets, must be valid hugging face write token\n",
    "  push_to_hub: true # set to true if you want to push the model to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "HF_USERNAME = userdata.get('HF_USERNAME')\n",
    "HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "os.environ['HF_USERNAME'] = HF_USERNAME\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "!autotrain --config config.yml"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
